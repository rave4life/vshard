test_run = require('test_run').new()
---
...
test_run:cmd("push filter '.*/init.lua.*[0-9]+: ' to ''")
---
- true
...
test_run:cmd("push filter 'lag: .+' to 'lag: <lag>'")
---
- true
...
test_run:cmd("push filter 'idle: .+' to 'idle: <idle>'")
---
- true
...
netbox = require('net.box')
---
...
fiber = require('fiber')
---
...
REPLICASET_1 = { 'storage_1_a', 'storage_1_b' }
---
...
REPLICASET_2 = { 'storage_2_a', 'storage_2_b' }
---
...
test_run:create_cluster(REPLICASET_1, 'storage')
---
...
test_run:create_cluster(REPLICASET_2, 'storage')
---
...
util = require('util')
---
...
util.wait_master(test_run, REPLICASET_1, 'storage_1_a')
---
...
util.wait_master(test_run, REPLICASET_2, 'storage_2_a')
---
...
replicaset1_uuid = test_run:eval('storage_1_a', 'box.info.cluster.uuid')[1]
---
...
replicaset2_uuid = test_run:eval('storage_2_a', 'box.info.cluster.uuid')[1]
---
...
test_run:cmd("push filter '"..replicaset1_uuid.."' to '<replicaset_1>'")
---
- true
...
test_run:cmd("push filter '"..replicaset2_uuid.."' to '<replicaset_2>'")
---
- true
...
storage_1_a_uuid = test_run:eval('storage_1_a', 'box.info.uuid')[1]
---
...
storage_1_b_uuid = test_run:eval('storage_1_b', 'box.info.uuid')[1]
---
...
storage_2_a_uuid = test_run:eval('storage_2_a', 'box.info.uuid')[1]
---
...
storage_2_b_uuid = test_run:eval('storage_2_b', 'box.info.uuid')[1]
---
...
test_run:cmd("push filter '"..storage_1_a_uuid.."' to '<storage_1_a>'")
---
- true
...
test_run:cmd("push filter '"..storage_1_b_uuid.."' to '<storage_1_b>'")
---
- true
...
test_run:cmd("push filter '"..storage_2_a_uuid.."' to '<storage_2_a>'")
---
- true
...
test_run:cmd("push filter '"..storage_2_b_uuid.."' to '<storage_2_b>'")
---
- true
...
_ = test_run:cmd("switch storage_1_a")
---
...
util = require('util')
---
...
vshard.storage.rebalancer_disable()
---
...
-- Ensure the trigger is called right after setting, and does not
-- wait until reconfiguration.
master_enabled = false
---
...
master_disabled = false
---
...
function on_master_enable() master_enabled = true end
---
...
function on_master_disable() master_disabled = true end
---
...
vshard.storage.on_master_enable(on_master_enable)
---
...
vshard.storage.on_master_disable(on_master_disable)
---
...
master_enabled
---
- true
...
master_disabled
---
- false
...
-- Test the same about master disabling.
test_run:switch('storage_1_b')
---
- true
...
master_enabled = false
---
...
master_disabled = false
---
...
function on_master_enable() master_enabled = true end
---
...
function on_master_disable() master_disabled = true end
---
...
vshard.storage.on_master_enable(on_master_enable)
---
...
vshard.storage.on_master_disable(on_master_disable)
---
...
master_enabled
---
- false
...
master_disabled
---
- true
...
test_run:switch('storage_1_a')
---
- true
...
replicaset1_uuid = test_run:eval('storage_1_a', 'box.info.cluster.uuid')[1]
---
...
replicaset2_uuid = test_run:eval('storage_2_a', 'box.info.cluster.uuid')[1]
---
...
vshard.storage.info().replicasets[replicaset1_uuid] or vshard.storage.info()
---
- uuid: <replicaset_1>
  master:
    uri: storage@127.0.0.1:3301
...
vshard.storage.info().replicasets[replicaset2_uuid] or vshard.storage.info()
---
- uuid: <replicaset_2>
  master:
    uri: storage@127.0.0.1:3303
...
-- Try to call info on a replicaset with no master.
rs1 = vshard.storage.internal.replicasets[replicaset1_uuid]
---
...
saved_master = rs1.master
---
...
rs1.master = nil
---
...
vshard.storage.info()
---
- replicasets:
    <replicaset_2>:
      uuid: <replicaset_2>
      master:
        uri: storage@127.0.0.1:3303
    <replicaset_1>:
      uuid: <replicaset_1>
      master: missing
  bucket:
    receiving: 0
    active: 0
    total: 0
    garbage: 0
    pinned: 0
    sending: 0
  status: 2
  replication:
    status: slave
  alerts:
  - ['MISSING_MASTER', 'Master is not configured for replicaset <replicaset_1>']
...
rs1.master = saved_master
---
...
-- Sync API
vshard.storage.sync()
---
- true
...
util.check_error(vshard.storage.sync, "xxx")
---
- 'Usage: vshard.storage.sync([timeout: number])'
...
vshard.storage.sync(100500)
---
- true
...
vshard.storage.buckets_info()
---
- {}
...
vshard.storage.bucket_force_create(1)
---
- true
...
vshard.storage.buckets_info()
---
- 1:
    status: active
    id: 1
...
vshard.storage.bucket_force_create(1) -- error
---
- null
- Duplicate key exists in unique index 'pk' in space '_bucket'
...
vshard.storage.bucket_force_drop(1)
---
- true
...
vshard.storage.buckets_info()
---
- {}
...
vshard.storage.bucket_force_create(1)
---
- true
...
vshard.storage.bucket_force_create(2)
---
- true
...
_ = test_run:cmd("switch storage_2_a")
---
...
vshard.storage.bucket_force_create(3)
---
- true
...
vshard.storage.bucket_force_create(4)
---
- true
...
_ = test_run:cmd("switch storage_2_b")
---
...
box.cfg{replication_timeout = 0.01}
---
...
vshard.storage.info()
---
- replicasets:
    <replicaset_2>:
      uuid: <replicaset_2>
      master:
        uri: storage@127.0.0.1:3303
    <replicaset_1>:
      uuid: <replicaset_1>
      master:
        uri: storage@127.0.0.1:3301
  bucket:
    receiving: 0
    active: 2
    total: 2
    garbage: 0
    pinned: 0
    sending: 0
  status: 0
  replication:
    status: follow
    lag: <lag>
  alerts: []
...
test_run:cmd("stop server storage_2_a")
---
- true
...
box.cfg{replication_timeout = 0.01}
---
...
vshard.storage.info()
---
- replicasets:
    <replicaset_2>:
      uuid: <replicaset_2>
      master:
        uri: storage@127.0.0.1:3303
    <replicaset_1>:
      uuid: <replicaset_1>
      master:
        uri: storage@127.0.0.1:3301
  bucket:
    receiving: 0
    active: 2
    total: 2
    garbage: 0
    pinned: 0
    sending: 0
  status: 1
  replication:
    status: disconnected
    idle: <idle>
  alerts:
  - ['UNREACHABLE_MASTER', 'Master of replicaset <replicaset_2>
      is unreachable: disconnected']
...
test_run:cmd("start server storage_2_a")
---
- true
...
test_run:cmd("switch storage_2_a")
---
- true
...
fiber = require('fiber')
---
...
info = vshard.storage.info()
---
...
while #info.alerts ~= 1 do fiber.sleep(0.1) info = vshard.storage.info() end
---
...
info
---
- replicasets:
    <replicaset_2>:
      uuid: <replicaset_2>
      master:
        state: active
        uri: storage@127.0.0.1:3303
        uuid: <storage_2_a>
    <replicaset_1>:
      uuid: <replicaset_1>
      master:
        state: active
        uri: storage@127.0.0.1:3301
        uuid: <storage_1_a>
  bucket:
    receiving: 0
    active: 2
    total: 2
    garbage: 0
    pinned: 0
    sending: 0
  status: 2
  replication:
    status: master
  alerts:
  - ['LOW_REDUNDANCY', 'Only one replica is active']
...
test_run:cmd("stop server storage_2_b")
---
- true
...
vshard.storage.info()
---
- replicasets:
    <replicaset_2>:
      uuid: <replicaset_2>
      master:
        state: active
        uri: storage@127.0.0.1:3303
        uuid: <storage_2_a>
    <replicaset_1>:
      uuid: <replicaset_1>
      master:
        state: active
        uri: storage@127.0.0.1:3301
        uuid: <storage_1_a>
  bucket:
    receiving: 0
    active: 2
    total: 2
    garbage: 0
    pinned: 0
    sending: 0
  status: 3
  replication:
    status: master
  alerts:
  - ['UNREACHABLE_REPLICA', 'Replica <storage_2_b> isn''t active']
  - ['UNREACHABLE_REPLICASET', 'There is no active replicas in replicaset <replicaset_2>']
...
test_run:cmd("start server storage_2_b")
---
- true
...
test_run:cmd("switch storage_2_b")
---
- true
...
vshard.storage.info()
---
- replicasets:
    <replicaset_2>:
      uuid: <replicaset_2>
      master:
        uri: storage@127.0.0.1:3303
    <replicaset_1>:
      uuid: <replicaset_1>
      master:
        uri: storage@127.0.0.1:3301
  bucket:
    receiving: 0
    active: 2
    total: 2
    garbage: 0
    pinned: 0
    sending: 0
  status: 0
  replication:
    status: follow
    lag: <lag>
  alerts: []
...
test_run:cmd("switch storage_2_a")
---
- true
...
vshard.storage.info()
---
- replicasets:
    <replicaset_2>:
      uuid: <replicaset_2>
      master:
        state: active
        uri: storage@127.0.0.1:3303
        uuid: <storage_2_a>
    <replicaset_1>:
      uuid: <replicaset_1>
      master:
        state: active
        uri: storage@127.0.0.1:3301
        uuid: <storage_1_a>
  bucket:
    receiving: 0
    active: 2
    total: 2
    garbage: 0
    pinned: 0
    sending: 0
  status: 2
  replication:
    status: master
  alerts:
  - ['LOW_REDUNDANCY', 'Only one replica is active']
...
_ = test_run:cmd("switch storage_1_a")
---
...
test_run:cmd("setopt delimiter ';'")
---
- true
...
box.begin()
for customer_id=1,8 do
    local bucket_id = customer_id % 4
    local name = string.format('Customer %d', customer_id)
    box.space.customer:insert({customer_id, bucket_id, name})
    for account_id=customer_id*10,customer_id*10+2 do
        local name = string.format('Account %d', account_id)
        box.space.account:insert({account_id, customer_id, bucket_id,
                                  100, name})
    end
end
box.commit();
---
...
test_run:cmd("setopt delimiter ''");
---
- true
...
box.space.customer:select()
---
- - [1, 1, 'Customer 1']
  - [2, 2, 'Customer 2']
  - [3, 3, 'Customer 3']
  - [4, 0, 'Customer 4']
  - [5, 1, 'Customer 5']
  - [6, 2, 'Customer 6']
  - [7, 3, 'Customer 7']
  - [8, 0, 'Customer 8']
...
box.space.account:select()
---
- - [10, 1, 1, 100, 'Account 10']
  - [11, 1, 1, 100, 'Account 11']
  - [12, 1, 1, 100, 'Account 12']
  - [20, 2, 2, 100, 'Account 20']
  - [21, 2, 2, 100, 'Account 21']
  - [22, 2, 2, 100, 'Account 22']
  - [30, 3, 3, 100, 'Account 30']
  - [31, 3, 3, 100, 'Account 31']
  - [32, 3, 3, 100, 'Account 32']
  - [40, 4, 0, 100, 'Account 40']
  - [41, 4, 0, 100, 'Account 41']
  - [42, 4, 0, 100, 'Account 42']
  - [50, 5, 1, 100, 'Account 50']
  - [51, 5, 1, 100, 'Account 51']
  - [52, 5, 1, 100, 'Account 52']
  - [60, 6, 2, 100, 'Account 60']
  - [61, 6, 2, 100, 'Account 61']
  - [62, 6, 2, 100, 'Account 62']
  - [70, 7, 3, 100, 'Account 70']
  - [71, 7, 3, 100, 'Account 71']
  - [72, 7, 3, 100, 'Account 72']
  - [80, 8, 0, 100, 'Account 80']
  - [81, 8, 0, 100, 'Account 81']
  - [82, 8, 0, 100, 'Account 82']
...
vshard.storage.bucket_collect(1)
---
- - - 514
    - - [10, 1, 1, 100, 'Account 10']
      - [11, 1, 1, 100, 'Account 11']
      - [12, 1, 1, 100, 'Account 12']
      - [50, 5, 1, 100, 'Account 50']
      - [51, 5, 1, 100, 'Account 51']
      - [52, 5, 1, 100, 'Account 52']
  - - 513
    - - [1, 1, 'Customer 1']
      - [5, 1, 'Customer 5']
...
vshard.storage.bucket_collect(2)
---
- - - 514
    - - [20, 2, 2, 100, 'Account 20']
      - [21, 2, 2, 100, 'Account 21']
      - [22, 2, 2, 100, 'Account 22']
      - [60, 6, 2, 100, 'Account 60']
      - [61, 6, 2, 100, 'Account 61']
      - [62, 6, 2, 100, 'Account 62']
  - - 513
    - - [2, 2, 'Customer 2']
      - [6, 2, 'Customer 6']
...
customer_lookup(1)
---
- accounts:
  - account_id: 10
    balance: 100
    name: Account 10
  - account_id: 11
    balance: 100
    name: Account 11
  - account_id: 12
    balance: 100
    name: Account 12
  customer_id: 1
  name: Customer 1
...
vshard.storage.call(1, 'read', 'customer_lookup', {1})
---
- true
- accounts:
  - account_id: 10
    balance: 100
    name: Account 10
  - account_id: 11
    balance: 100
    name: Account 11
  - account_id: 12
    balance: 100
    name: Account 12
  customer_id: 1
  name: Customer 1
...
vshard.storage.call(100500, 'read', 'customer_lookup', {1})
---
- null
- bucket_id: 100500
  reason: Not found
  code: 1
  type: ShardingError
  message: 'Cannot perform action with bucket 100500, reason: Not found'
  name: WRONG_BUCKET
...
--
-- Test not existing space in bucket data.
--
vshard.storage.bucket_recv(100, 'from_uuid', {{1000, {{1}}}})
---
- null
- type: ClientError
  code: 36
  message: Space '1000' does not exist
  trace:
  - file: '[C]'
    line: 4294967295
...
--
-- Bucket transfer
--
-- Transfer to unknown replicaset.
vshard.storage.bucket_send(1, 'unknown uuid')
---
- null
- code: 4
  type: ShardingError
  name: NO_SUCH_REPLICASET
  replicaset_uuid: unknown uuid
  message: Replicaset unknown uuid not found
...
-- Successful transfer.
vshard.storage.bucket_send(1, replicaset2_uuid)
---
- true
...
_ = test_run:cmd("switch storage_2_a")
---
...
vshard.storage.buckets_info()
---
- 1:
    status: active
    id: 1
  3:
    status: active
    id: 3
  4:
    status: active
    id: 4
...
_ = test_run:cmd("switch storage_1_a")
---
...
vshard.storage.buckets_info()
---
- 1:
    status: sent
    destination: <replicaset_2>
    id: 1
  2:
    status: active
    id: 2
...
--
-- Part of gh-76: check that netbox old connections are reused on
-- reconfiguration.
--
old_connections = {}
---
...
connection_count = 0
---
...
old_replicasets = vshard.storage.internal.replicasets
---
...
test_run:cmd("setopt delimiter ';'")
---
- true
...
for _, old_replicaset in pairs(old_replicasets) do
	for uuid, old_replica in pairs(old_replicaset.replicas) do
		old_connections[uuid] = old_replica.conn
		if old_replica.conn then
			connection_count = connection_count + 1
		end
	end
end;
---
...
test_run:cmd("setopt delimiter ''");
---
- true
...
connection_count > 0
---
- true
...
vshard.storage.cfg(cfg, names.storage_1_a)
---
...
new_replicasets = vshard.storage.internal.replicasets
---
...
new_replicasets ~= old_replicasets
---
- true
...
test_run:cmd("setopt delimiter ';'")
---
- true
...
for _, new_replicaset in pairs(new_replicasets) do
	for uuid, new_replica in pairs(new_replicaset.replicas) do
		assert(old_connections[uuid] == new_replica.conn)
	end
end;
---
...
test_run:cmd("setopt delimiter ''");
---
- true
...
-- gh-114: Check non-dynamic option change during reconfigure.
non_dynamic_cfg = table.copy(cfg)
---
...
non_dynamic_cfg.bucket_count = require('vshard.consts').DEFAULT_BUCKET_COUNT + 1
---
...
util.check_error(vshard.storage.cfg, non_dynamic_cfg, names.storage_1_a)
---
- Non-dynamic option bucket_count cannot be reconfigured
...
-- Error during reconfigure process.
_, rs = next(vshard.storage.internal.replicasets)
---
...
rs:callro('echo', {'some_data'})
---
- some_data
- null
- null
...
vshard.storage.internal.errinj.ERRINJ_CFG = true
---
...
old_internal = table.copy(vshard.storage.internal)
---
...
_, err = pcall(vshard.storage.cfg, cfg, names.storage_1_a)
---
...
err:match('Error injection:.*')
---
- 'Error injection: cfg'
...
vshard.storage.internal.errinj.ERRINJ_CFG = false
---
...
util.has_same_fields(old_internal, vshard.storage.internal)
---
- true
...
_, rs = next(vshard.storage.internal.replicasets)
---
...
rs:callro('echo', {'some_data'})
---
- some_data
- null
- null
...
_ = test_run:cmd("switch default")
---
...
test_run:drop_cluster(REPLICASET_2)
---
...
test_run:drop_cluster(REPLICASET_1)
---
...
test_run:cmd('clear filter')
---
- true
...
